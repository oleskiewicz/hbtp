#!/usr/bin/env python
import sys
import h5py
import numpy as np
import pandas as pd

import logging
from logging.config import fileConfig
fileConfig("./log.conf")
log = logging.getLogger()

columns = [\
	["nodeIndex", "descendantIndex", "snapshotNumber", "particleNumber",
	"hostIndex", "descendantHost", "isMainProgenitor",],\
	["int64", "int64", "int32", "int32", "int64", "int64", "int32",],\
]

def mock(data_frame=False):
	"""Returns a tiny mock dataset

	Arguments:
		data_frame (bool): whether to return a DataFrame or NumPy array (default is
		NumPy array)
	Returns:
		numpy.ndarray / pandas.DataFrame: small dataset, suitable for testing
			algorithms in :mod:`src.tree`
	"""
	d = np.array([[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9],     # nodeIndex
                [-1, 0, 1, 1, 3, 3,-1, 6, 7, 1],     # descendantIndex
                [ 4, 3, 2, 2, 1, 1, 4, 3, 2, 2],     # snapshotNumber
                [10, 8, 3, 5, 2, 3, 4, 4, 4, 2]]).T  # particleNumber
	if data_frame:
		d = pd.DataFrame(d, columns=columns[0:4])
	return d

def data(file_hdf5, file_numpy=None, data_frame=False):
	"""Reads DHalo data into memory

	**Output data format:**

	===========  ==================
	 Column ID    Column Name
	===========  ==================
	         0    nodeIndex        
	         1    descendantIndex  
	         2    snapshotNumber   
	         3    particleNumber   
	         4    hostIndex        
	         5    descendantHost   
	         6    isMainProgenitor 
	===========  ==================
	
	nodeIndex:
		index of each halo or subhalo, unique across the entire catalogue
	descendantIndex:
		index of a descendanta halo (if multiple haloes have the same descendatant
		index, they all are the progenitors)
	snapshotNumber:
		snapshot at which halo was identified
	particleNumber:
		number of particles in a halo; might differ from masses identified by other
		methods
	hostIndex:
		index of a host halo; for subhaloes, this points to a parent halo; for main
		haloes, this points to themselves
	descendantHost:
		index of a host halo of descendant of a halo (or subhalo); this field
		eliminates "multiple descendance" problem, always creating a merger history
		which works for main progenitors only
	isMainProgenitor:
		1 if it is

	Arguments:
		file_hdf5 (str): filename of an HDF5 data store
		file_numpy (str): filename to which NumPy array object can be saved (for
			faster re-reads);  this is later used for faster data retrieval in
			:func:`src.read.retrieve`;  if ``None``, no data is cached
		data_frame (bool): whether to return a DataFrame or not (default not, returns
			NumPy array)

	Returns:
		numpy.ndarray / pandas.DataFrame:  DHalo catalogue

	Example:
		To retrieve a single halo of ``nodeIndex=123``, run:

		.. code-block:: python

			d = read.data()
			h = d[np.where(d[:,ID] == 123)][0]
	"""

	f = h5py.File(file_hdf5, 'r')

	d = np.core.records.fromarrays([np.array(f['/haloTrees/%s'%column].value) \
		for column in columns[0]], names = columns[0], formats = columns[1])

	# d[0] = np.array([0 for column in columns])

	if file_numpy is not None:
		with open(file_numpy, 'w') as file_numpy:
			np.save(file_numpy, d)

	if data_frame:
		d = pd.DataFrame(d, columns=columns[0])
		d.index = d.nodeIndex

	f.close()
	return d

def retrieve(file_numpy):
	"""Loads data saved in a NumPy binary format instead of HDF5 catalogue, as
	provided by :func:`src.read.data`

	Arguments:
		file_numpy (str): source of NumPy binary store generated by
		  :func:`src.read.data`
	"""
	return np.load(open(file_numpy, 'r'))

if __name__ == '__main__':
	file_hdf5, file_numpy = sys.argv[1], sys.argv[2]
	log.info("Reading %s"%file_hdf5)
	d = data(file_hdf5, file_numpy)
	log.info("Saved to %s"%file_numpy)

